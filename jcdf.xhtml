<html>
<head>
<title>JCDF</title>
</head>
<body>
<h1>JCDF</h1>

<h2>Overview</h2>

<p>JCDF is a pure java library capable of reading files in the
<a href="http://cdf.gsfc.nasa.gov/">Common Data Format</a> defined by NASA.
It runs within the J2SE1.5 (or later), but other than that has no dependencies,
neither the official CDF C library nor any other java class libraries.
</p>

<h2>Documentation</h2>

<p>The classes are provided with comprehensive
<a href="javadocs/index.html">javadocs</a>.
Start reading at the
<a href="javadocs/uk/ac/bristol/star/cdf/CdfContent.html"
                                  ><code>CdfContent</code></a> class
for high-level access to CDF data and metadata, or
<a href="javadocs/uk/ac/bristol/star/cdf/CdfReader.html"
                                  ><code>CdfReader</code></a>
for low-level access to the CDF internal records.
</p>

<h2>Comparison with the official CDF library</h2>

<p>JCDF is a completely separate implementation from the Java interface to
the official CDF library, which uses native code via JNI.
It was written mainly with reference to the CDF Internal Format Description
document (v3.4).
</p>

<p>The main benefit of using JCDF, and the reason for developing it, 
is that it's pure java, so it can be deployed using only the JCDF jar file.  
There is no need to install the system-dependent official CDF library.
</p>

<p>The API is very different from that of the official CDF library.
JCDF gives you a simple view of the CDF file, in terms of its 
global attributes, variable attributes and variables.
This is fairly easy to use, but may or may not suit your purposes.
It's also possible to get a low-level view of the CDF file as a 
sequence of CDF records.
</p>

<p>JCDF offers no capabilities for writing or editing CDF files,
it only reads them.
</p>

<p>JCDF is based on NIO mapped ByteBuffers, it's expected to be reasonably
fast, but I haven't done any benchmarking.
</p>

<h2>Implementation Status</h2>

<p>Support for the CDF format is fairly, but not totally, complete.
In particular:
</p>
<ul>
<li><strong>Versions:</strong>
    The code was written with reference to version 3.4 of
    the CDF Internal Format Description document.
    Following comments in that document, it is believed that 
    versions 2.6, 2.7 and 3.* of the CDF format are supported.
    Maybe others.
    </li>
<li><strong>Large files:</strong>
    The library imposes no restriction on file size,
    so &gt;2Gb files should be OK for v3 CDF files (CDF v2 did not
    support 64-bit addressing) as long as a 64-bit JVM is in use.
    However, I haven't tested on large files, because I haven't seen one yet.
    Contributions welcome.
    </li>
<li><strong>Compression:</strong>
    All formats supported (GZIP, HUFF, AHUFF, RLE).
    </li>
<li><strong>Numeric encodings:</strong>
    Normal big- and little-endian encodings supported,
    but VMS D_FLOAT and G_FLOAT encodings are not supported.
    </li>
<li><strong>Layout:</strong>
    Single-file CDF files are supported, but multiple-file CDF files are not.
    This could be added fairly easily if necessary.
    </li>
<li><strong>I/O:</strong>
    Access is read-only, there is no attempt or intention
    to support write access.
    </li>
<li><strong>Data types:</strong>
    All CDF data types are supported, more or less.
    Unsigned integer types are transformed to larger signed types on read,
    because of the difficulty of handling unsigned integers in java,
    so for instance a CDF_UINT1 is read as a java <code>short</code> (16-bit)
    integer.
    The time formats CDF_EPOCH, CDF_EPOCH16 and CDF_TIME_TT2000 are currently
    treated as <code>double</code>, <code>double[2]</code> and <code>long</code>
    respectively, i.e. are not obviously times.
    </li>
<li><strong>Record data access</strong>:
    For array-valued variables you can currently only read a whole record
    at a time, not just part of an array-valued record.
    You can either get the raw elements or a shaped version.
    This is considerably less flexible than a hyper-read.
    </li>
</ul>

<h2>Utilities</h2>

<p>The library comes with a couple of simple utilities for examining
CDF files:
</p>
<dl>
<dt><strong><code>CdfList</code></strong>:</dt>
<dd>displays the metadata and data from a CDF file,
    along the lines of the <code>cdfdump</code> command in the official
    CDF distribution.
    If the <code>-data</code> flag is supplied, record data as well as
    metadata is shown.
    See <a href="cdflist.html">CdfList examples</a>.
    </dd>
<dt><strong><code>CdfDump</code></strong>:</dt>
<dd>displays a dump of the sequence of low-level
    CDF records found in the CDF fil, along the lines of the
    <code>cdfirsdump</code> command in the official CDF distribution.
    If the <code>-fields</code> flag is supplied, field information from
    each record is shown.  If the <code>-html</code> flag is supplied,
    the output is in HTML with files offsets displayed as hyperlinks,
    which is nice for chasing pointers.
    See <a href="cdfdump.html">CdfDump examples</a>.
    </dd>
</dl>

<h2>Downloads</h2>

<p>The source code is hosted on github at
<a href="https://github.com/mbtaylor/jcdf">https://github.com/mbtaylor/jcdf</a>.
It comes with a makefile that can be used to build the jar file,
javadocs, and this documentation, and to run some tests.
</p>

<p>Pre-built copies of the jar file and documentation
for the current version (v0.1) can be found here:
</p>
<ul>
<li><a href="jcdf.jar">jcdf.jar</a></li>
<li><a href="javadocs/index.html">javadocs</a></li>
</ul>
<p>Previous versions may be available at
<a href="ftp://andromeda.star.bris.ac.uk/pub/star/jcdf/"
        >ftp://andromeda.star.bris.ac.uk/pub/star/jcdf/</a>.
</p>

<h2>History</h2>

<dl>
<dt><strong>Version 0.1 (28 Jun 2013)</strong></dt>
<dd>Initial release.
    Tested, documented and believed working, though could use some
    more testing and perhaps functionality related to time-related DataTypes.
    </dd>
<dt><strong>next version</strong></dt>
<dd><ul>
    <li>Fix failure when reading non-sparse variables with zero records.</li>
    <li>Fix big error in TIME_TT2000 data type formatting.
        There still seems to be an error of about a minute, something to
        do with leap seconds (not treated) at least, possibly something
        else too, but it's in the right ball park.</li>
    <li>TIME_TT2000 default pad value now reported as special case value
        0AD rather than 1707AD.</li>
    <li>Fix bug: pad values not explicitly defined are given default values
        rather than causing an error.</li>
    <li>Fix EPOCH16 bug.</li>
    </ul>
    </dd>
</dl>

<h2>Context</h2>

<p>This software was written by 
<a href="http://www.star.bristol.ac.uk/~mbt/">Mark Taylor</a>
at the University of Bristol at the request of, and funded by,
the science archive group at ESA's European Space Astronomy Centre (ESAC).
</p>

<p>It is used within
   <a href="http://www.starlink.ac.uk/topcat/">TOPCAT</a
 >/<a href="http://www.starlink.ac.uk/stilts/">STILTS</a
 >/<a href="http://www.starlink.ac.uk/stil/">STIL</a>
to enable access to CDF tables alongside other tabular data formats
by that software.
</p>

<p>It is licenced under the LGPL, though if you need a different licence
I can probably fix it.
</p>

<p>Bugs, questions, feedback welcome to
<a href="mailto:m.b.taylor@bristol.ac.uk">m.b.taylor@bristol.ac.uk</a>.
</p>

<address>
<hr />
Mark Taylor --
<a href='http://www.phy.bris.ac.uk/groups/astrophysics/'
       >Astrophysics Group</a>,
<a href='http://www.phy.bris.ac.uk/'>School of Physics</a>,
<a href='http://www.bris.ac.uk/'>Bristol University</a>
</address>
</body>
</html>
